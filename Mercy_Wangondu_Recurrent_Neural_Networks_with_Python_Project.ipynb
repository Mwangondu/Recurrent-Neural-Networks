{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mercy Wangondu: Recurrent Neural Networks with Python - Project",
      "provenance": [],
      "collapsed_sections": [
        "kLG2VTrnTvYL",
        "XecOwPNorl2W",
        "J4wfHZwQrs-t",
        "a9BPYqunry97",
        "7KMRBJ7zr9HD",
        "n8tP5QFQEcy2",
        "yPaOYgFMEemO",
        "uVLc3iMCE48d",
        "D4Qz7YGGHbee",
        "cnkCNAuEHlzG",
        "y5_spjYaHoyw",
        "i5BnrlDxU5uG"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymYoNMngEbN1"
      },
      "source": [
        "# <font color='#2F4F4F'>AfterWork Data Science: Recurrent Neural Networks with Python - Project</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLG2VTrnTvYL"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 1. Business Understanding </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XecOwPNorl2W"
      },
      "source": [
        "### a) Specifying the Research Question\n",
        "\n",
        "Build a recurrent neural networks model that will be used to predict Tesla stock prices in 2017 using data from 2012-2016"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4wfHZwQrs-t"
      },
      "source": [
        "### b) Defining the Metric for Success\n",
        "\n",
        "Build a neural networks regression model with an RSME  less than 10% of the target mean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BPYqunry97"
      },
      "source": [
        "### c) Understanding the Context \n",
        "\n",
        "Stockpy is an innovative fintech enabling financial prosperity for the entire population. It is a venture funded startup based in Palo Alto bringing world-class financial experiences to a continually growing customer base. As Stockpy enters an expansion phase for innovative fintech product offerings, it aims to enhance the enormous value in data processing and analysis for continuous growth and success.\n",
        "\n",
        "As a Finance Data Scientist for Stockpy, you provide leadership to turn cutting-edge technology into actionable insights; unlocking the power of data that provides value to business decisions and customer service enhancements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMRBJ7zr9HD"
      },
      "source": [
        "### d) Recording the Experimental Design\n",
        "\n",
        "* Business Understanding\n",
        "* Data Exploration\n",
        "* Data Preparation\n",
        "* Data Modeling and Evaluation\n",
        "* Summary of Findings and Recommendation\n",
        "* Challenging the Solution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8tP5QFQEcy2"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 2. Data Importation</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIjcefBSy7I_"
      },
      "source": [
        "# Importing standard libraries\n",
        "# ---\n",
        "# \n",
        "import pandas as pd               # library for data manipulation\n",
        "import numpy as np                # library for scientific computations\n",
        "import matplotlib.pyplot as plt   # library for data visualisation "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmLxWeu1DTP9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0fbbde3d-3657-4a5b-ba84-f1b008b7a586"
      },
      "source": [
        "# Importing train dataset\n",
        "# ---\n",
        "#\n",
        "train_df =pd.read_csv('https://bit.ly/38dSbSb')\n",
        "train_df.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8279bd3d-23fd-4523-bec1-61daea3dec76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>5.788</td>\n",
              "      <td>5.900</td>\n",
              "      <td>5.530</td>\n",
              "      <td>5.616</td>\n",
              "      <td>5.616</td>\n",
              "      <td>4640500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-04</td>\n",
              "      <td>5.642</td>\n",
              "      <td>5.734</td>\n",
              "      <td>5.500</td>\n",
              "      <td>5.542</td>\n",
              "      <td>5.542</td>\n",
              "      <td>3150500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-05</td>\n",
              "      <td>5.552</td>\n",
              "      <td>5.586</td>\n",
              "      <td>5.370</td>\n",
              "      <td>5.424</td>\n",
              "      <td>5.424</td>\n",
              "      <td>5027500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-06</td>\n",
              "      <td>5.440</td>\n",
              "      <td>5.558</td>\n",
              "      <td>5.282</td>\n",
              "      <td>5.382</td>\n",
              "      <td>5.382</td>\n",
              "      <td>4931500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-09</td>\n",
              "      <td>5.400</td>\n",
              "      <td>5.498</td>\n",
              "      <td>5.224</td>\n",
              "      <td>5.450</td>\n",
              "      <td>5.450</td>\n",
              "      <td>4485000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8279bd3d-23fd-4523-bec1-61daea3dec76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8279bd3d-23fd-4523-bec1-61daea3dec76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8279bd3d-23fd-4523-bec1-61daea3dec76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Date   Open   High    Low  Close  Adj Close   Volume\n",
              "0  2012-01-03  5.788  5.900  5.530  5.616      5.616  4640500\n",
              "1  2012-01-04  5.642  5.734  5.500  5.542      5.542  3150500\n",
              "2  2012-01-05  5.552  5.586  5.370  5.424      5.424  5027500\n",
              "3  2012-01-06  5.440  5.558  5.282  5.382      5.382  4931500\n",
              "4  2012-01-09  5.400  5.498  5.224  5.450      5.450  4485000"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing test dataset\n",
        "# ---\n",
        "#\n",
        "test_set =pd.read_csv('https://bit.ly/38dSbSb')\n",
        "test_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "V6vWesnhuTz-",
        "outputId": "944376b4-845d-4964-fd5b-b523c0a556fa"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-841b387f-bc9f-490e-b0a8-c12d1c03f906\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>5.788</td>\n",
              "      <td>5.900</td>\n",
              "      <td>5.530</td>\n",
              "      <td>5.616</td>\n",
              "      <td>5.616</td>\n",
              "      <td>4640500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-04</td>\n",
              "      <td>5.642</td>\n",
              "      <td>5.734</td>\n",
              "      <td>5.500</td>\n",
              "      <td>5.542</td>\n",
              "      <td>5.542</td>\n",
              "      <td>3150500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-05</td>\n",
              "      <td>5.552</td>\n",
              "      <td>5.586</td>\n",
              "      <td>5.370</td>\n",
              "      <td>5.424</td>\n",
              "      <td>5.424</td>\n",
              "      <td>5027500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-06</td>\n",
              "      <td>5.440</td>\n",
              "      <td>5.558</td>\n",
              "      <td>5.282</td>\n",
              "      <td>5.382</td>\n",
              "      <td>5.382</td>\n",
              "      <td>4931500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-09</td>\n",
              "      <td>5.400</td>\n",
              "      <td>5.498</td>\n",
              "      <td>5.224</td>\n",
              "      <td>5.450</td>\n",
              "      <td>5.450</td>\n",
              "      <td>4485000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-841b387f-bc9f-490e-b0a8-c12d1c03f906')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-841b387f-bc9f-490e-b0a8-c12d1c03f906 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-841b387f-bc9f-490e-b0a8-c12d1c03f906');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Date   Open   High    Low  Close  Adj Close   Volume\n",
              "0  2012-01-03  5.788  5.900  5.530  5.616      5.616  4640500\n",
              "1  2012-01-04  5.642  5.734  5.500  5.542      5.542  3150500\n",
              "2  2012-01-05  5.552  5.586  5.370  5.424      5.424  5027500\n",
              "3  2012-01-06  5.440  5.558  5.282  5.382      5.382  4931500\n",
              "4  2012-01-09  5.400  5.498  5.224  5.450      5.450  4485000"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPaOYgFMEemO"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 3. Data Exploration</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2HpkzRPJGVn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "8c698499-001e-4644-e3f8-c529a1b5dbae"
      },
      "source": [
        "# Sample dataset\n",
        "# ---\n",
        "#\n",
        "train_df.sample(10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b2e6bbb7-7b25-4d90-be5d-cfaf064e41ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>882</th>\n",
              "      <td>2015-07-08</td>\n",
              "      <td>51.863998</td>\n",
              "      <td>52.160000</td>\n",
              "      <td>50.862000</td>\n",
              "      <td>50.992001</td>\n",
              "      <td>50.992001</td>\n",
              "      <td>31105500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>906</th>\n",
              "      <td>2015-08-11</td>\n",
              "      <td>47.430000</td>\n",
              "      <td>47.860001</td>\n",
              "      <td>46.888000</td>\n",
              "      <td>47.473999</td>\n",
              "      <td>47.473999</td>\n",
              "      <td>21324500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1202</th>\n",
              "      <td>2016-10-12</td>\n",
              "      <td>40.189999</td>\n",
              "      <td>40.776001</td>\n",
              "      <td>40.084000</td>\n",
              "      <td>40.301998</td>\n",
              "      <td>40.301998</td>\n",
              "      <td>9853500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>2015-12-16</td>\n",
              "      <td>44.419998</td>\n",
              "      <td>46.976002</td>\n",
              "      <td>44.146000</td>\n",
              "      <td>46.902000</td>\n",
              "      <td>46.902000</td>\n",
              "      <td>25521500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>2015-02-12</td>\n",
              "      <td>38.714001</td>\n",
              "      <td>40.618000</td>\n",
              "      <td>38.655998</td>\n",
              "      <td>40.576000</td>\n",
              "      <td>40.576000</td>\n",
              "      <td>78248000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>2015-04-14</td>\n",
              "      <td>41.714001</td>\n",
              "      <td>41.897999</td>\n",
              "      <td>41.099998</td>\n",
              "      <td>41.492001</td>\n",
              "      <td>41.492001</td>\n",
              "      <td>15130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>2012-08-30</td>\n",
              "      <td>5.720000</td>\n",
              "      <td>5.748000</td>\n",
              "      <td>5.620000</td>\n",
              "      <td>5.682000</td>\n",
              "      <td>5.682000</td>\n",
              "      <td>3282000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>2015-12-07</td>\n",
              "      <td>45.540001</td>\n",
              "      <td>47.125999</td>\n",
              "      <td>45.230000</td>\n",
              "      <td>46.226002</td>\n",
              "      <td>46.226002</td>\n",
              "      <td>15721000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>2015-12-21</td>\n",
              "      <td>46.338001</td>\n",
              "      <td>47.166000</td>\n",
              "      <td>46.216000</td>\n",
              "      <td>46.512001</td>\n",
              "      <td>46.512001</td>\n",
              "      <td>9766000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>949</th>\n",
              "      <td>2015-10-12</td>\n",
              "      <td>44.598000</td>\n",
              "      <td>44.599998</td>\n",
              "      <td>43.054001</td>\n",
              "      <td>43.116001</td>\n",
              "      <td>43.116001</td>\n",
              "      <td>19181500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2e6bbb7-7b25-4d90-be5d-cfaf064e41ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2e6bbb7-7b25-4d90-be5d-cfaf064e41ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2e6bbb7-7b25-4d90-be5d-cfaf064e41ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Date       Open       High  ...      Close  Adj Close    Volume\n",
              "882   2015-07-08  51.863998  52.160000  ...  50.992001  50.992001  31105500\n",
              "906   2015-08-11  47.430000  47.860001  ...  47.473999  47.473999  21324500\n",
              "1202  2016-10-12  40.189999  40.776001  ...  40.301998  40.301998   9853500\n",
              "995   2015-12-16  44.419998  46.976002  ...  46.902000  46.902000  25521500\n",
              "782   2015-02-12  38.714001  40.618000  ...  40.576000  40.576000  78248000\n",
              "823   2015-04-14  41.714001  41.897999  ...  41.492001  41.492001  15130000\n",
              "167   2012-08-30   5.720000   5.748000  ...   5.682000   5.682000   3282000\n",
              "988   2015-12-07  45.540001  47.125999  ...  46.226002  46.226002  15721000\n",
              "998   2015-12-21  46.338001  47.166000  ...  46.512001  46.512001   9766000\n",
              "949   2015-10-12  44.598000  44.599998  ...  43.116001  43.116001  19181500\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiORNaHaE5f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "983738b9-73c8-416a-e7f8-88d0458e3a11"
      },
      "source": [
        "# Statistical summary\n",
        "# ---\n",
        "#\n",
        "train_df.describe()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bb83eac7-845d-4540-a458-17b3a97dab40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1258.000000</td>\n",
              "      <td>1258.000000</td>\n",
              "      <td>1258.000000</td>\n",
              "      <td>1258.000000</td>\n",
              "      <td>1258.000000</td>\n",
              "      <td>1.258000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>31.997898</td>\n",
              "      <td>32.558671</td>\n",
              "      <td>31.403696</td>\n",
              "      <td>31.989245</td>\n",
              "      <td>31.989245</td>\n",
              "      <td>2.551310e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16.911515</td>\n",
              "      <td>17.148543</td>\n",
              "      <td>16.649245</td>\n",
              "      <td>16.903500</td>\n",
              "      <td>16.903500</td>\n",
              "      <td>2.259037e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.324000</td>\n",
              "      <td>5.370000</td>\n",
              "      <td>4.528000</td>\n",
              "      <td>4.558000</td>\n",
              "      <td>4.558000</td>\n",
              "      <td>1.824500e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.403000</td>\n",
              "      <td>8.556000</td>\n",
              "      <td>8.197000</td>\n",
              "      <td>8.379500</td>\n",
              "      <td>8.379500</td>\n",
              "      <td>1.059400e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>39.411000</td>\n",
              "      <td>40.123998</td>\n",
              "      <td>38.709000</td>\n",
              "      <td>39.427000</td>\n",
              "      <td>39.427000</td>\n",
              "      <td>2.007650e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>45.214499</td>\n",
              "      <td>45.934999</td>\n",
              "      <td>44.303000</td>\n",
              "      <td>45.076502</td>\n",
              "      <td>45.076502</td>\n",
              "      <td>3.245150e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>57.534000</td>\n",
              "      <td>58.284000</td>\n",
              "      <td>56.080002</td>\n",
              "      <td>57.208000</td>\n",
              "      <td>57.208000</td>\n",
              "      <td>1.858195e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb83eac7-845d-4540-a458-17b3a97dab40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb83eac7-845d-4540-a458-17b3a97dab40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb83eac7-845d-4540-a458-17b3a97dab40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              Open         High  ...    Adj Close        Volume\n",
              "count  1258.000000  1258.000000  ...  1258.000000  1.258000e+03\n",
              "mean     31.997898    32.558671  ...    31.989245  2.551310e+07\n",
              "std      16.911515    17.148543  ...    16.903500  2.259037e+07\n",
              "min       5.324000     5.370000  ...     4.558000  1.824500e+06\n",
              "25%       8.403000     8.556000  ...     8.379500  1.059400e+07\n",
              "50%      39.411000    40.123998  ...    39.427000  2.007650e+07\n",
              "75%      45.214499    45.934999  ...    45.076502  3.245150e+07\n",
              "max      57.534000    58.284000  ...    57.208000  1.858195e+08\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVLc3iMCE48d"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 4. Data Preparation</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DD5qpc3Ivyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6884d1ab-028a-4695-fd67-ab78b3476ccd"
      },
      "source": [
        "# Getting our train dataset\n",
        "# ---\n",
        "#we are interested in stock prices in 2017 using data from 2012-2016 therefore our in train set data will be the opening price\n",
        "train_set = train_df.iloc[:,1:2].values\n",
        "train_set"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.788   ],\n",
              "       [ 5.642   ],\n",
              "       [ 5.552   ],\n",
              "       ...,\n",
              "       [44.306   ],\n",
              "       [43.712002],\n",
              "       [43.259998]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBavdYmaDaQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f9a0ee-1e3f-41fd-b040-f6b41d7b20d8"
      },
      "source": [
        "# Performing Feature scaling\n",
        "# ---\n",
        "#\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "train_set_scaled = sc.fit_transform(train_set)\n",
        "train_set_scaled"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00888719],\n",
              "       [0.00609079],\n",
              "       [0.00436698],\n",
              "       ...,\n",
              "       [0.74663857],\n",
              "       [0.73526148],\n",
              "       [0.72660406]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdkim4BCDgdi"
      },
      "source": [
        "# Creating a dataset with 60 timesteps and 1 output\n",
        "# ---\n",
        "#\n",
        "# ---\n",
        "# A special data structure is needed to cover 60-time stamps, based on which RNN will predict the 61st price. \n",
        "# The number of past timestamps is set to 60 based on experimentation.\n",
        "# Thus, X_train is a nested list, which contains lists of 60 time-stamp prices. \n",
        "# y_train is a list of stock prices which is the next day stock price, corresponding to each list in X_train.\n",
        "# ---\n",
        "#\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60, len(train_df)):\n",
        "    X_train.append(train_set_scaled[i-60:i, 0])\n",
        "    y_train.append(train_set_scaled[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcSQM2x8DlhI"
      },
      "source": [
        "# Reshaping \n",
        "# ---\n",
        "#\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vNVpyaWVj5f",
        "outputId": "326fc3d3-c160-4275-aed1-77779c7beeaf"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1198, 60, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4Qz7YGGHbee"
      },
      "source": [
        "##  <font color='#2F4F4F'>Step 5. Data Modeling</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSKGzmRNDtpV"
      },
      "source": [
        "# Building the RNN\n",
        "# ---\n",
        "#\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-oXw1R5Dy7T"
      },
      "source": [
        "# Initialising the RNN\n",
        "# ---\n",
        "#\n",
        "regressor = Sequential()\n",
        "\n",
        "# Adding 4 LSTM layers and some Dropout regularisation\n",
        "\n",
        "# 'units' is the number of LSTM neurons in the layer\n",
        "# 'return_sequences' is True as we need to add another LSTM layer after the current one.\n",
        "# 'input_shape' corresponds to the number of time stamps and the number of indicators.\n",
        "#  For 'Dropout', 20% of 50 neurons will be ignored randomly during each iteration of training.\n",
        "# ---\n",
        "# Adding the first LSTM layer and some Dropout regularisation\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "# 'return_sequences' is False as we will not add more LSTM layers after this one.\n",
        "regressor.add(LSTM(units = 50, return_sequences = False))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# Adding the output layer\n",
        "# 'output dimension' is 1 since we are predicting 1 price each time.\n",
        "regressor.add(Dense(units = 1))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nsqxXskD3IX"
      },
      "source": [
        "# Compile the RNN \n",
        "# ---\n",
        "#\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obcll9uYD6od",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de98a960-644b-449d-ccae-7d639ac37366"
      },
      "source": [
        "# Fitting the RNN to the training set\n",
        "# ---\n",
        "#\n",
        "regressor.fit(X_train, y_train, epochs = 200, batch_size = 32)\n",
        "# model.fit(X_train, y_train, epochs = 200, batch_size = 32, validation_data = (X_test, y_test))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0065 - accuracy: 8.3472e-04\n",
            "Epoch 2/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0065 - accuracy: 8.3472e-04\n",
            "Epoch 3/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0059 - accuracy: 8.3472e-04\n",
            "Epoch 4/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0053 - accuracy: 8.3472e-04\n",
            "Epoch 5/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0053 - accuracy: 8.3472e-04\n",
            "Epoch 6/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0054 - accuracy: 8.3472e-04\n",
            "Epoch 7/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0059 - accuracy: 8.3472e-04\n",
            "Epoch 8/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0054 - accuracy: 8.3472e-04\n",
            "Epoch 9/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0046 - accuracy: 8.3472e-04\n",
            "Epoch 10/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0047 - accuracy: 8.3472e-04\n",
            "Epoch 11/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0039 - accuracy: 8.3472e-04\n",
            "Epoch 12/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0040 - accuracy: 8.3472e-04\n",
            "Epoch 13/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0044 - accuracy: 8.3472e-04\n",
            "Epoch 14/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0044 - accuracy: 8.3472e-04\n",
            "Epoch 15/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0041 - accuracy: 8.3472e-04\n",
            "Epoch 16/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0051 - accuracy: 8.3472e-04\n",
            "Epoch 17/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0044 - accuracy: 8.3472e-04\n",
            "Epoch 18/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0041 - accuracy: 8.3472e-04\n",
            "Epoch 19/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0044 - accuracy: 8.3472e-04\n",
            "Epoch 20/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0042 - accuracy: 8.3472e-04\n",
            "Epoch 21/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0038 - accuracy: 8.3472e-04\n",
            "Epoch 22/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0036 - accuracy: 8.3472e-04\n",
            "Epoch 23/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0040 - accuracy: 8.3472e-04\n",
            "Epoch 24/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0039 - accuracy: 8.3472e-04\n",
            "Epoch 25/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0036 - accuracy: 8.3472e-04\n",
            "Epoch 26/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0036 - accuracy: 8.3472e-04\n",
            "Epoch 27/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0036 - accuracy: 8.3472e-04\n",
            "Epoch 28/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0035 - accuracy: 8.3472e-04\n",
            "Epoch 29/200\n",
            "38/38 [==============================] - 3s 66ms/step - loss: 0.0036 - accuracy: 8.3472e-04\n",
            "Epoch 30/200\n",
            "38/38 [==============================] - 3s 69ms/step - loss: 0.0034 - accuracy: 8.3472e-04\n",
            "Epoch 31/200\n",
            "38/38 [==============================] - 3s 69ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 32/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 33/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 34/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0032 - accuracy: 8.3472e-04\n",
            "Epoch 35/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0030 - accuracy: 8.3472e-04\n",
            "Epoch 36/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 37/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0035 - accuracy: 8.3472e-04\n",
            "Epoch 38/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0034 - accuracy: 8.3472e-04\n",
            "Epoch 39/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 40/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0032 - accuracy: 8.3472e-04\n",
            "Epoch 41/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0029 - accuracy: 8.3472e-04\n",
            "Epoch 42/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0028 - accuracy: 8.3472e-04\n",
            "Epoch 43/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0032 - accuracy: 8.3472e-04\n",
            "Epoch 44/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0030 - accuracy: 8.3472e-04\n",
            "Epoch 45/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0028 - accuracy: 8.3472e-04\n",
            "Epoch 46/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0027 - accuracy: 8.3472e-04\n",
            "Epoch 47/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0027 - accuracy: 8.3472e-04\n",
            "Epoch 48/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0030 - accuracy: 8.3472e-04\n",
            "Epoch 49/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0030 - accuracy: 8.3472e-04\n",
            "Epoch 50/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0027 - accuracy: 8.3472e-04\n",
            "Epoch 51/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0027 - accuracy: 8.3472e-04\n",
            "Epoch 52/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0028 - accuracy: 8.3472e-04\n",
            "Epoch 53/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0028 - accuracy: 8.3472e-04\n",
            "Epoch 54/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0027 - accuracy: 8.3472e-04\n",
            "Epoch 55/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 56/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0028 - accuracy: 8.3472e-04\n",
            "Epoch 57/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0024 - accuracy: 8.3472e-04\n",
            "Epoch 58/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0025 - accuracy: 8.3472e-04\n",
            "Epoch 59/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 60/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0025 - accuracy: 8.3472e-04\n",
            "Epoch 61/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0024 - accuracy: 8.3472e-04\n",
            "Epoch 62/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 63/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0026 - accuracy: 8.3472e-04\n",
            "Epoch 64/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0024 - accuracy: 8.3472e-04\n",
            "Epoch 65/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 66/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0022 - accuracy: 8.3472e-04\n",
            "Epoch 67/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 68/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0024 - accuracy: 8.3472e-04\n",
            "Epoch 69/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 70/200\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 71/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0022 - accuracy: 8.3472e-04\n",
            "Epoch 72/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 73/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 74/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 75/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 76/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 77/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 78/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 79/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 80/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 81/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0022 - accuracy: 8.3472e-04\n",
            "Epoch 82/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 83/200\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 84/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 85/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 86/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 87/200\n",
            "38/38 [==============================] - 3s 66ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 88/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 89/200\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 90/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 91/200\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 92/200\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 93/200\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 94/200\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 95/200\n",
            "38/38 [==============================] - 3s 69ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 96/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 97/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 98/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 99/200\n",
            "38/38 [==============================] - 3s 66ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 100/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 101/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 102/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 103/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 104/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 105/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 106/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 107/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 108/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 109/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 110/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 111/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 112/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 113/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 114/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 115/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 116/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 117/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 118/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 119/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 120/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 121/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 122/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 123/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 124/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 125/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 126/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 127/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 128/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 129/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 130/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 131/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 132/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 133/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 134/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 135/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 136/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 137/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 138/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 139/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 140/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 141/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 142/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 143/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 144/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 145/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 146/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 147/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 148/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 149/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 150/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 151/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 152/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 153/200\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 154/200\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 155/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 156/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 157/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 158/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 159/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 160/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 161/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 162/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 163/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 164/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 165/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 166/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 167/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 168/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 169/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 170/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 171/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 172/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 173/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 174/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 175/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 176/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 177/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 178/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 179/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 180/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 181/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 182/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 183/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 184/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 185/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 186/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 187/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 188/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 189/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 190/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 191/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 192/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 193/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 194/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 195/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 196/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 197/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 198/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 199/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 200/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ffa7b2610>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nywLR70_w_Or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1ac96e-2f3d-4588-d52d-6c36c2d46f80"
      },
      "source": [
        "# Making predictions: Getting the predicted stock price for 2017\n",
        "# ---\n",
        "#\n",
        "real_stock_price = test_set.iloc[:, 1:2].values\n",
        "print(real_stock_price)\n",
        "\n",
        "\n",
        "# ---\n",
        "# We need to concatenate the train and test datasets for prediction, \n",
        "# because we use the previous 60 days' stock prices to predict the next-day price. \n",
        "# i.e. we need the 60 days' price before the 1st date in the test dataset.\n",
        "# ---\n",
        "#\n",
        "dataset_total = pd.concat((train_df['Open'],test_set['Open']), axis=0)\n",
        "\n",
        "# We create the input for prediction, index starting from the \n",
        "# date 60 days before the first date in the test dataset.\n",
        "# ---\n",
        "#\n",
        "inputs = dataset_total[len(dataset_total)-len(test_set)-60:].values\n",
        "\n",
        "\n",
        "# Reshaping the inputs to have only 1 column\n",
        "# ---\n",
        "#\n",
        "inputs = inputs.reshape(-1, 1)\n",
        "\n",
        "\n",
        "# Using the scale set by the training set to scale the test inputs\n",
        "# ---\n",
        "#\n",
        "inputs = sc.transform(inputs)\n",
        "\n",
        "\n",
        "# Then creating the test data structure just as we did for the train dataset\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "for i in range(60, len(inputs)):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "    y_test.append(inputs[i, 0])\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Making our Predictions\n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "\n",
        "# reversing the scaled values\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
        "print(predicted_stock_price)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5.788   ]\n",
            " [ 5.642   ]\n",
            " [ 5.552   ]\n",
            " ...\n",
            " [44.306   ]\n",
            " [43.712002]\n",
            " [43.259998]]\n",
            "[[43.018   ]\n",
            " [29.293749]\n",
            " [19.670069]\n",
            " ...\n",
            " [42.432713]\n",
            " [43.703293]\n",
            " [43.416653]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the results\n",
        "plt.plot(real_stock_price, color = 'blue', label = 'Real Tesla Stock Price')\n",
        "plt.plot(predicted_stock_price, color = 'red', label = 'Predicted Tesla Stock Price')\n",
        "plt.title('Tesla Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Tesla Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "uY472BaWBfTu",
        "outputId": "3c101b50-e92e-445a-e175-7428344ea426"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DawtOvbkdRHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ace721-5fb8-4588-c82b-68bf391017a9"
      },
      "source": [
        "# Model Evaluation\n",
        "# ---\n",
        "#\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "rmse = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))\n",
        "print(rmse)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8231715040694545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# target mean=31.997898\n",
        "perc_of_mean = 1.8231715040694545/31.997898\n",
        "perc_of_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPXaW1QIaNBt",
        "outputId": "98747236-632d-486f-f4ba-76d25afa9df2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05697785223483913"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnkCNAuEHlzG"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 6. Summary of Findings and Recommendation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA2cp-dIMgki"
      },
      "source": [
        "Findings:\n",
        "\n",
        "The predicted stock price does not differ much from the actual meaning our model is fairly accurate,\n",
        "We achieved an RMSE 5.6% of the target mean.\n",
        "\n",
        "Recommendation:\n",
        "We can use RNN model to predict the stock prices farily acccurately\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5_spjYaHoyw"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 7. Challenging our Solution</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5BnrlDxU5uG"
      },
      "source": [
        "#### a) Did we have the right question?\n",
        "We had the right questions for our analysis\n",
        "\n",
        "#### b) Did we have the right data?\n",
        "We had the right data for our analysis\n",
        "\n",
        "#### c) What can be done to improve the solution?\n",
        "We can improve the performance of our model by adding more LSTM layers, increasng our training data and increasing the timesteps"
      ]
    }
  ]
}