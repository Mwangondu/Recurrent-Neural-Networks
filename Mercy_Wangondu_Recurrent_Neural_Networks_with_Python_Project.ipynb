{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mercy Wangondu: Recurrent Neural Networks with Python - Project",
      "provenance": [],
      "collapsed_sections": [
        "J4wfHZwQrs-t",
        "a9BPYqunry97",
        "7KMRBJ7zr9HD",
        "i5BnrlDxU5uG"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymYoNMngEbN1"
      },
      "source": [
        "# <font color='#2F4F4F'>AfterWork Data Science: Recurrent Neural Networks with Python - Project</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLG2VTrnTvYL"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 1. Business Understanding </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XecOwPNorl2W"
      },
      "source": [
        "### a) Specifying the Research Question\n",
        "\n",
        "Build a recurrent neural networks model that will be used to predict Tesla stock prices in 2017 using data from 2012-2016"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4wfHZwQrs-t"
      },
      "source": [
        "### b) Defining the Metric for Success\n",
        "\n",
        "Build a neural networks regression model with an RSME  less than 10% of the target mean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BPYqunry97"
      },
      "source": [
        "### c) Understanding the Context \n",
        "\n",
        "Stockpy is an innovative fintech enabling financial prosperity for the entire population. It is a venture funded startup based in Palo Alto bringing world-class financial experiences to a continually growing customer base. As Stockpy enters an expansion phase for innovative fintech product offerings, it aims to enhance the enormous value in data processing and analysis for continuous growth and success.\n",
        "\n",
        "As a Finance Data Scientist for Stockpy, you provide leadership to turn cutting-edge technology into actionable insights; unlocking the power of data that provides value to business decisions and customer service enhancements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMRBJ7zr9HD"
      },
      "source": [
        "### d) Recording the Experimental Design\n",
        "\n",
        "* Business Understanding\n",
        "* Data Exploration\n",
        "* Data Preparation\n",
        "* Data Modeling and Evaluation\n",
        "* Summary of Findings and Recommendation\n",
        "* Challenging the Solution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8tP5QFQEcy2"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 2. Data Importation</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIjcefBSy7I_"
      },
      "source": [
        "# Importing standard libraries\n",
        "# ---\n",
        "# \n",
        "import pandas as pd               # library for data manipulation\n",
        "import numpy as np                # library for scientific computations\n",
        "import matplotlib.pyplot as plt   # library for data visualisation "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmLxWeu1DTP9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0fbbde3d-3657-4a5b-ba84-f1b008b7a586"
      },
      "source": [
        "# Importing train dataset\n",
        "# ---\n",
        "#\n",
        "train_df =pd.read_csv('https://bit.ly/38dSbSb')\n",
        "train_df.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8279bd3d-23fd-4523-bec1-61daea3dec76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>5.788</td>\n",
              "      <td>5.900</td>\n",
              "      <td>5.530</td>\n",
              "      <td>5.616</td>\n",
              "      <td>5.616</td>\n",
              "      <td>4640500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-04</td>\n",
              "      <td>5.642</td>\n",
              "      <td>5.734</td>\n",
              "      <td>5.500</td>\n",
              "      <td>5.542</td>\n",
              "      <td>5.542</td>\n",
              "      <td>3150500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-05</td>\n",
              "      <td>5.552</td>\n",
              "      <td>5.586</td>\n",
              "      <td>5.370</td>\n",
              "      <td>5.424</td>\n",
              "      <td>5.424</td>\n",
              "      <td>5027500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-06</td>\n",
              "      <td>5.440</td>\n",
              "      <td>5.558</td>\n",
              "      <td>5.282</td>\n",
              "      <td>5.382</td>\n",
              "      <td>5.382</td>\n",
              "      <td>4931500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-09</td>\n",
              "      <td>5.400</td>\n",
              "      <td>5.498</td>\n",
              "      <td>5.224</td>\n",
              "      <td>5.450</td>\n",
              "      <td>5.450</td>\n",
              "      <td>4485000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8279bd3d-23fd-4523-bec1-61daea3dec76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8279bd3d-23fd-4523-bec1-61daea3dec76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8279bd3d-23fd-4523-bec1-61daea3dec76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Date   Open   High    Low  Close  Adj Close   Volume\n",
              "0  2012-01-03  5.788  5.900  5.530  5.616      5.616  4640500\n",
              "1  2012-01-04  5.642  5.734  5.500  5.542      5.542  3150500\n",
              "2  2012-01-05  5.552  5.586  5.370  5.424      5.424  5027500\n",
              "3  2012-01-06  5.440  5.558  5.282  5.382      5.382  4931500\n",
              "4  2012-01-09  5.400  5.498  5.224  5.450      5.450  4485000"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing test dataset\n",
        "# ---\n",
        "#\n",
        "test_set =pd.read_csv('https://bit.ly/38dSbSb')\n",
        "test_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "V6vWesnhuTz-",
        "outputId": "944376b4-845d-4964-fd5b-b523c0a556fa"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-841b387f-bc9f-490e-b0a8-c12d1c03f906\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-03</td>\n",
              "      <td>5.788</td>\n",
              "      <td>5.900</td>\n",
              "      <td>5.530</td>\n",
              "      <td>5.616</td>\n",
              "      <td>5.616</td>\n",
              "      <td>4640500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-04</td>\n",
              "      <td>5.642</td>\n",
              "      <td>5.734</td>\n",
              "      <td>5.500</td>\n",
              "      <td>5.542</td>\n",
              "      <td>5.542</td>\n",
              "      <td>3150500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-05</td>\n",
              "      <td>5.552</td>\n",
              "      <td>5.586</td>\n",
              "      <td>5.370</td>\n",
              "      <td>5.424</td>\n",
              "      <td>5.424</td>\n",
              "      <td>5027500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-06</td>\n",
              "      <td>5.440</td>\n",
              "      <td>5.558</td>\n",
              "      <td>5.282</td>\n",
              "      <td>5.382</td>\n",
              "      <td>5.382</td>\n",
              "      <td>4931500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-09</td>\n",
              "      <td>5.400</td>\n",
              "      <td>5.498</td>\n",
              "      <td>5.224</td>\n",
              "      <td>5.450</td>\n",
              "      <td>5.450</td>\n",
              "      <td>4485000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-841b387f-bc9f-490e-b0a8-c12d1c03f906')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-841b387f-bc9f-490e-b0a8-c12d1c03f906 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-841b387f-bc9f-490e-b0a8-c12d1c03f906');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Date   Open   High    Low  Close  Adj Close   Volume\n",
              "0  2012-01-03  5.788  5.900  5.530  5.616      5.616  4640500\n",
              "1  2012-01-04  5.642  5.734  5.500  5.542      5.542  3150500\n",
              "2  2012-01-05  5.552  5.586  5.370  5.424      5.424  5027500\n",
              "3  2012-01-06  5.440  5.558  5.282  5.382      5.382  4931500\n",
              "4  2012-01-09  5.400  5.498  5.224  5.450      5.450  4485000"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPaOYgFMEemO"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 3. Data Exploration</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2HpkzRPJGVn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "8c698499-001e-4644-e3f8-c529a1b5dbae"
      },
      "source": [
        "# Sample dataset\n",
        "# ---\n",
        "#\n",
        "train_df.sample(10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b2e6bbb7-7b25-4d90-be5d-cfaf064e41ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>882</th>\n",
              "      <td>2015-07-08</td>\n",
              "      <td>51.863998</td>\n",
              "      <td>52.160000</td>\n",
              "      <td>50.862000</td>\n",
              "      <td>50.992001</td>\n",
              "      <td>50.992001</td>\n",
              "      <td>31105500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>906</th>\n",
              "      <td>2015-08-11</td>\n",
              "      <td>47.430000</td>\n",
              "      <td>47.860001</td>\n",
              "      <td>46.888000</td>\n",
              "      <td>47.473999</td>\n",
              "      <td>47.473999</td>\n",
              "      <td>21324500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1202</th>\n",
              "      <td>2016-10-12</td>\n",
              "      <td>40.189999</td>\n",
              "      <td>40.776001</td>\n",
              "      <td>40.084000</td>\n",
              "      <td>40.301998</td>\n",
              "      <td>40.301998</td>\n",
              "      <td>9853500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>2015-12-16</td>\n",
              "      <td>44.419998</td>\n",
              "      <td>46.976002</td>\n",
              "      <td>44.146000</td>\n",
              "      <td>46.902000</td>\n",
              "      <td>46.902000</td>\n",
              "      <td>25521500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>2015-02-12</td>\n",
              "      <td>38.714001</td>\n",
              "      <td>40.618000</td>\n",
              "      <td>38.655998</td>\n",
              "      <td>40.576000</td>\n",
              "      <td>40.576000</td>\n",
              "      <td>78248000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>2015-04-14</td>\n",
              "      <td>41.714001</td>\n",
              "      <td>41.897999</td>\n",
              "      <td>41.099998</td>\n",
              "      <td>41.492001</td>\n",
              "      <td>41.492001</td>\n",
              "      <td>15130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>2012-08-30</td>\n",
              "      <td>5.720000</td>\n",
              "      <td>5.748000</td>\n",
              "      <td>5.620000</td>\n",
              "      <td>5.682000</td>\n",
              "      <td>5.682000</td>\n",
              "      <td>3282000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>2015-12-07</td>\n",
              "      <td>45.540001</td>\n",
              "      <td>47.125999</td>\n",
              "      <td>45.230000</td>\n",
              "      <td>46.226002</td>\n",
              "      <td>46.226002</td>\n",
              "      <td>15721000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>2015-12-21</td>\n",
              "      <td>46.338001</td>\n",
              "      <td>47.166000</td>\n",
              "      <td>46.216000</td>\n",
              "      <td>46.512001</td>\n",
              "      <td>46.512001</td>\n",
              "      <td>9766000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>949</th>\n",
              "      <td>2015-10-12</td>\n",
              "      <td>44.598000</td>\n",
              "      <td>44.599998</td>\n",
              "      <td>43.054001</td>\n",
              "      <td>43.116001</td>\n",
              "      <td>43.116001</td>\n",
              "      <td>19181500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2e6bbb7-7b25-4d90-be5d-cfaf064e41ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2e6bbb7-7b25-4d90-be5d-cfaf064e41ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2e6bbb7-7b25-4d90-be5d-cfaf064e41ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Date       Open       High  ...      Close  Adj Close    Volume\n",
              "882   2015-07-08  51.863998  52.160000  ...  50.992001  50.992001  31105500\n",
              "906   2015-08-11  47.430000  47.860001  ...  47.473999  47.473999  21324500\n",
              "1202  2016-10-12  40.189999  40.776001  ...  40.301998  40.301998   9853500\n",
              "995   2015-12-16  44.419998  46.976002  ...  46.902000  46.902000  25521500\n",
              "782   2015-02-12  38.714001  40.618000  ...  40.576000  40.576000  78248000\n",
              "823   2015-04-14  41.714001  41.897999  ...  41.492001  41.492001  15130000\n",
              "167   2012-08-30   5.720000   5.748000  ...   5.682000   5.682000   3282000\n",
              "988   2015-12-07  45.540001  47.125999  ...  46.226002  46.226002  15721000\n",
              "998   2015-12-21  46.338001  47.166000  ...  46.512001  46.512001   9766000\n",
              "949   2015-10-12  44.598000  44.599998  ...  43.116001  43.116001  19181500\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiORNaHaE5f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "983738b9-73c8-416a-e7f8-88d0458e3a11"
      },
      "source": [
        "# Statistical summary\n",
        "# ---\n",
        "#\n",
        "train_df.describe()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bb83eac7-845d-4540-a458-17b3a97dab40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1258.000000</td>\n",
              "      <td>1258.000000</td>\n",
              "      <td>1258.000000</td>\n",
              "      <td>1258.000000</td>\n",
              "      <td>1258.000000</td>\n",
              "      <td>1.258000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>31.997898</td>\n",
              "      <td>32.558671</td>\n",
              "      <td>31.403696</td>\n",
              "      <td>31.989245</td>\n",
              "      <td>31.989245</td>\n",
              "      <td>2.551310e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16.911515</td>\n",
              "      <td>17.148543</td>\n",
              "      <td>16.649245</td>\n",
              "      <td>16.903500</td>\n",
              "      <td>16.903500</td>\n",
              "      <td>2.259037e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.324000</td>\n",
              "      <td>5.370000</td>\n",
              "      <td>4.528000</td>\n",
              "      <td>4.558000</td>\n",
              "      <td>4.558000</td>\n",
              "      <td>1.824500e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.403000</td>\n",
              "      <td>8.556000</td>\n",
              "      <td>8.197000</td>\n",
              "      <td>8.379500</td>\n",
              "      <td>8.379500</td>\n",
              "      <td>1.059400e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>39.411000</td>\n",
              "      <td>40.123998</td>\n",
              "      <td>38.709000</td>\n",
              "      <td>39.427000</td>\n",
              "      <td>39.427000</td>\n",
              "      <td>2.007650e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>45.214499</td>\n",
              "      <td>45.934999</td>\n",
              "      <td>44.303000</td>\n",
              "      <td>45.076502</td>\n",
              "      <td>45.076502</td>\n",
              "      <td>3.245150e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>57.534000</td>\n",
              "      <td>58.284000</td>\n",
              "      <td>56.080002</td>\n",
              "      <td>57.208000</td>\n",
              "      <td>57.208000</td>\n",
              "      <td>1.858195e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb83eac7-845d-4540-a458-17b3a97dab40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb83eac7-845d-4540-a458-17b3a97dab40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb83eac7-845d-4540-a458-17b3a97dab40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              Open         High  ...    Adj Close        Volume\n",
              "count  1258.000000  1258.000000  ...  1258.000000  1.258000e+03\n",
              "mean     31.997898    32.558671  ...    31.989245  2.551310e+07\n",
              "std      16.911515    17.148543  ...    16.903500  2.259037e+07\n",
              "min       5.324000     5.370000  ...     4.558000  1.824500e+06\n",
              "25%       8.403000     8.556000  ...     8.379500  1.059400e+07\n",
              "50%      39.411000    40.123998  ...    39.427000  2.007650e+07\n",
              "75%      45.214499    45.934999  ...    45.076502  3.245150e+07\n",
              "max      57.534000    58.284000  ...    57.208000  1.858195e+08\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVLc3iMCE48d"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 4. Data Preparation</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DD5qpc3Ivyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6884d1ab-028a-4695-fd67-ab78b3476ccd"
      },
      "source": [
        "# Getting our train dataset\n",
        "# ---\n",
        "#we are interested in stock prices in 2017 using data from 2012-2016 therefore our in train set data will be the opening price\n",
        "train_set = train_df.iloc[:,1:2].values\n",
        "train_set"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.788   ],\n",
              "       [ 5.642   ],\n",
              "       [ 5.552   ],\n",
              "       ...,\n",
              "       [44.306   ],\n",
              "       [43.712002],\n",
              "       [43.259998]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBavdYmaDaQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f9a0ee-1e3f-41fd-b040-f6b41d7b20d8"
      },
      "source": [
        "# Performing Feature scaling\n",
        "# ---\n",
        "#\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "train_set_scaled = sc.fit_transform(train_set)\n",
        "train_set_scaled"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00888719],\n",
              "       [0.00609079],\n",
              "       [0.00436698],\n",
              "       ...,\n",
              "       [0.74663857],\n",
              "       [0.73526148],\n",
              "       [0.72660406]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdkim4BCDgdi"
      },
      "source": [
        "# Creating a dataset with 60 timesteps and 1 output\n",
        "# ---\n",
        "#\n",
        "# ---\n",
        "# A special data structure is needed to cover 60-time stamps, based on which RNN will predict the 61st price. \n",
        "# The number of past timestamps is set to 60 based on experimentation.\n",
        "# Thus, X_train is a nested list, which contains lists of 60 time-stamp prices. \n",
        "# y_train is a list of stock prices which is the next day stock price, corresponding to each list in X_train.\n",
        "# ---\n",
        "#\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60, len(train_df)):\n",
        "    X_train.append(train_set_scaled[i-60:i, 0])\n",
        "    y_train.append(train_set_scaled[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcSQM2x8DlhI"
      },
      "source": [
        "# Reshaping \n",
        "# ---\n",
        "#\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vNVpyaWVj5f",
        "outputId": "326fc3d3-c160-4275-aed1-77779c7beeaf"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1198, 60, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4Qz7YGGHbee"
      },
      "source": [
        "##  <font color='#2F4F4F'>Step 5. Data Modeling</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSKGzmRNDtpV"
      },
      "source": [
        "# Building the RNN\n",
        "# ---\n",
        "#\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-oXw1R5Dy7T"
      },
      "source": [
        "# Initialising the RNN\n",
        "# ---\n",
        "#\n",
        "regressor = Sequential()\n",
        "\n",
        "# Adding 4 LSTM layers and some Dropout regularisation\n",
        "\n",
        "# 'units' is the number of LSTM neurons in the layer\n",
        "# 'return_sequences' is True as we need to add another LSTM layer after the current one.\n",
        "# 'input_shape' corresponds to the number of time stamps and the number of indicators.\n",
        "#  For 'Dropout', 20% of 50 neurons will be ignored randomly during each iteration of training.\n",
        "# ---\n",
        "# Adding the first LSTM layer and some Dropout regularisation\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "# 'return_sequences' is False as we will not add more LSTM layers after this one.\n",
        "regressor.add(LSTM(units = 50, return_sequences = False))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# Adding the output layer\n",
        "# 'output dimension' is 1 since we are predicting 1 price each time.\n",
        "regressor.add(Dense(units = 1))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nsqxXskD3IX"
      },
      "source": [
        "# Compile the RNN \n",
        "# ---\n",
        "#\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obcll9uYD6od",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de98a960-644b-449d-ccae-7d639ac37366"
      },
      "source": [
        "# Fitting the RNN to the training set\n",
        "# ---\n",
        "#\n",
        "regressor.fit(X_train, y_train, epochs = 200, batch_size = 32)\n",
        "# model.fit(X_train, y_train, epochs = 200, batch_size = 32, validation_data = (X_test, y_test))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0065 - accuracy: 8.3472e-04\n",
            "Epoch 2/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0065 - accuracy: 8.3472e-04\n",
            "Epoch 3/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0059 - accuracy: 8.3472e-04\n",
            "Epoch 4/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0053 - accuracy: 8.3472e-04\n",
            "Epoch 5/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0053 - accuracy: 8.3472e-04\n",
            "Epoch 6/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0054 - accuracy: 8.3472e-04\n",
            "Epoch 7/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0059 - accuracy: 8.3472e-04\n",
            "Epoch 8/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0054 - accuracy: 8.3472e-04\n",
            "Epoch 9/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0046 - accuracy: 8.3472e-04\n",
            "Epoch 10/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0047 - accuracy: 8.3472e-04\n",
            "Epoch 11/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0039 - accuracy: 8.3472e-04\n",
            "Epoch 12/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0040 - accuracy: 8.3472e-04\n",
            "Epoch 13/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0044 - accuracy: 8.3472e-04\n",
            "Epoch 14/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0044 - accuracy: 8.3472e-04\n",
            "Epoch 15/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0041 - accuracy: 8.3472e-04\n",
            "Epoch 16/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0051 - accuracy: 8.3472e-04\n",
            "Epoch 17/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0044 - accuracy: 8.3472e-04\n",
            "Epoch 18/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0041 - accuracy: 8.3472e-04\n",
            "Epoch 19/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0044 - accuracy: 8.3472e-04\n",
            "Epoch 20/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0042 - accuracy: 8.3472e-04\n",
            "Epoch 21/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0038 - accuracy: 8.3472e-04\n",
            "Epoch 22/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0036 - accuracy: 8.3472e-04\n",
            "Epoch 23/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0040 - accuracy: 8.3472e-04\n",
            "Epoch 24/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0039 - accuracy: 8.3472e-04\n",
            "Epoch 25/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0036 - accuracy: 8.3472e-04\n",
            "Epoch 26/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0036 - accuracy: 8.3472e-04\n",
            "Epoch 27/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0036 - accuracy: 8.3472e-04\n",
            "Epoch 28/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0035 - accuracy: 8.3472e-04\n",
            "Epoch 29/200\n",
            "38/38 [==============================] - 3s 66ms/step - loss: 0.0036 - accuracy: 8.3472e-04\n",
            "Epoch 30/200\n",
            "38/38 [==============================] - 3s 69ms/step - loss: 0.0034 - accuracy: 8.3472e-04\n",
            "Epoch 31/200\n",
            "38/38 [==============================] - 3s 69ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 32/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 33/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 34/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0032 - accuracy: 8.3472e-04\n",
            "Epoch 35/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0030 - accuracy: 8.3472e-04\n",
            "Epoch 36/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 37/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0035 - accuracy: 8.3472e-04\n",
            "Epoch 38/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0034 - accuracy: 8.3472e-04\n",
            "Epoch 39/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 40/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0032 - accuracy: 8.3472e-04\n",
            "Epoch 41/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0029 - accuracy: 8.3472e-04\n",
            "Epoch 42/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0028 - accuracy: 8.3472e-04\n",
            "Epoch 43/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0032 - accuracy: 8.3472e-04\n",
            "Epoch 44/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0030 - accuracy: 8.3472e-04\n",
            "Epoch 45/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0028 - accuracy: 8.3472e-04\n",
            "Epoch 46/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0027 - accuracy: 8.3472e-04\n",
            "Epoch 47/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0027 - accuracy: 8.3472e-04\n",
            "Epoch 48/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0030 - accuracy: 8.3472e-04\n",
            "Epoch 49/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0030 - accuracy: 8.3472e-04\n",
            "Epoch 50/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0027 - accuracy: 8.3472e-04\n",
            "Epoch 51/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0027 - accuracy: 8.3472e-04\n",
            "Epoch 52/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0028 - accuracy: 8.3472e-04\n",
            "Epoch 53/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0028 - accuracy: 8.3472e-04\n",
            "Epoch 54/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0027 - accuracy: 8.3472e-04\n",
            "Epoch 55/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0033 - accuracy: 8.3472e-04\n",
            "Epoch 56/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0028 - accuracy: 8.3472e-04\n",
            "Epoch 57/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0024 - accuracy: 8.3472e-04\n",
            "Epoch 58/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0025 - accuracy: 8.3472e-04\n",
            "Epoch 59/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 60/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0025 - accuracy: 8.3472e-04\n",
            "Epoch 61/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0024 - accuracy: 8.3472e-04\n",
            "Epoch 62/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 63/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0026 - accuracy: 8.3472e-04\n",
            "Epoch 64/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0024 - accuracy: 8.3472e-04\n",
            "Epoch 65/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 66/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0022 - accuracy: 8.3472e-04\n",
            "Epoch 67/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 68/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0024 - accuracy: 8.3472e-04\n",
            "Epoch 69/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 70/200\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 71/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0022 - accuracy: 8.3472e-04\n",
            "Epoch 72/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 73/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 74/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 75/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 76/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 77/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 78/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 79/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0023 - accuracy: 8.3472e-04\n",
            "Epoch 80/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 81/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0022 - accuracy: 8.3472e-04\n",
            "Epoch 82/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 83/200\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 84/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0021 - accuracy: 8.3472e-04\n",
            "Epoch 85/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 86/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 87/200\n",
            "38/38 [==============================] - 3s 66ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 88/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 89/200\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 90/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 91/200\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 92/200\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 93/200\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 94/200\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 95/200\n",
            "38/38 [==============================] - 3s 69ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 96/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 97/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 98/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 99/200\n",
            "38/38 [==============================] - 3s 66ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 100/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 101/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 102/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 103/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 104/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 105/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 106/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 107/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 108/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 109/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 110/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 111/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 112/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 113/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 114/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 115/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 116/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 117/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 118/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0018 - accuracy: 8.3472e-04\n",
            "Epoch 119/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 120/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0020 - accuracy: 8.3472e-04\n",
            "Epoch 121/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 122/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 123/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 124/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 125/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 126/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 127/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 128/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 129/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 130/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 131/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 132/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 133/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 134/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 135/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 136/200\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0019 - accuracy: 8.3472e-04\n",
            "Epoch 137/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 138/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 139/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 140/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 141/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 142/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 143/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 144/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 145/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 146/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 147/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 148/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 149/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 150/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 151/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 152/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 153/200\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 154/200\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 155/200\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 156/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 157/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 158/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 159/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 160/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 161/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 162/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 163/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 164/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 165/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 166/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 167/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 168/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 169/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 170/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 171/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0017 - accuracy: 8.3472e-04\n",
            "Epoch 172/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 173/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 174/200\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 175/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 176/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 177/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 178/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 179/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 180/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0016 - accuracy: 8.3472e-04\n",
            "Epoch 181/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 182/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 183/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 184/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 185/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 186/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 187/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 188/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 189/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 190/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 191/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 192/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 193/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 194/200\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 195/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 196/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0015 - accuracy: 8.3472e-04\n",
            "Epoch 197/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 198/200\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n",
            "Epoch 199/200\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0014 - accuracy: 8.3472e-04\n",
            "Epoch 200/200\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0013 - accuracy: 8.3472e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ffa7b2610>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nywLR70_w_Or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1ac96e-2f3d-4588-d52d-6c36c2d46f80"
      },
      "source": [
        "# Making predictions: Getting the predicted stock price for 2017\n",
        "# ---\n",
        "#\n",
        "real_stock_price = test_set.iloc[:, 1:2].values\n",
        "print(real_stock_price)\n",
        "\n",
        "\n",
        "# ---\n",
        "# We need to concatenate the train and test datasets for prediction, \n",
        "# because we use the previous 60 days' stock prices to predict the next-day price. \n",
        "# i.e. we need the 60 days' price before the 1st date in the test dataset.\n",
        "# ---\n",
        "#\n",
        "dataset_total = pd.concat((train_df['Open'],test_set['Open']), axis=0)\n",
        "\n",
        "# We create the input for prediction, index starting from the \n",
        "# date 60 days before the first date in the test dataset.\n",
        "# ---\n",
        "#\n",
        "inputs = dataset_total[len(dataset_total)-len(test_set)-60:].values\n",
        "\n",
        "\n",
        "# Reshaping the inputs to have only 1 column\n",
        "# ---\n",
        "#\n",
        "inputs = inputs.reshape(-1, 1)\n",
        "\n",
        "\n",
        "# Using the scale set by the training set to scale the test inputs\n",
        "# ---\n",
        "#\n",
        "inputs = sc.transform(inputs)\n",
        "\n",
        "\n",
        "# Then creating the test data structure just as we did for the train dataset\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "for i in range(60, len(inputs)):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "    y_test.append(inputs[i, 0])\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Making our Predictions\n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "\n",
        "# reversing the scaled values\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
        "print(predicted_stock_price)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5.788   ]\n",
            " [ 5.642   ]\n",
            " [ 5.552   ]\n",
            " ...\n",
            " [44.306   ]\n",
            " [43.712002]\n",
            " [43.259998]]\n",
            "[[43.018   ]\n",
            " [29.293749]\n",
            " [19.670069]\n",
            " ...\n",
            " [42.432713]\n",
            " [43.703293]\n",
            " [43.416653]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the results\n",
        "plt.plot(real_stock_price, color = 'blue', label = 'Real Stockpy Stock Price')\n",
        "plt.plot(predicted_stock_price, color = 'red', label = 'Predicted Stockpy Stock Price')\n",
        "plt.title('Stockpy Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stockpy Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "uY472BaWBfTu",
        "outputId": "f165d9b0-9ce8-4ee0-8c73-97d2d2f521d7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DawtOvbkdRHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ace721-5fb8-4588-c82b-68bf391017a9"
      },
      "source": [
        "# Model Evaluation\n",
        "# ---\n",
        "#\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "rmse = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))\n",
        "print(rmse)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8231715040694545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# target mean=31.997898\n",
        "perc_of_mean = 1.8231715040694545/31.997898\n",
        "perc_of_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPXaW1QIaNBt",
        "outputId": "98747236-632d-486f-f4ba-76d25afa9df2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05697785223483913"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnkCNAuEHlzG"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 6. Summary of Findings and Recommendation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA2cp-dIMgki"
      },
      "source": [
        "Findings:\n",
        "\n",
        "The predicted stock price does not differ much from the actual meaning our model is fairly accurate,\n",
        "We achieved an RMSE 5.6% of the target mean.\n",
        "\n",
        "Recommendation:\n",
        "We can use RNN model to predict the stock prices farily acccurately\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5_spjYaHoyw"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 7. Challenging our Solution</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5BnrlDxU5uG"
      },
      "source": [
        "#### a) Did we have the right question?\n",
        "We had the right questions for our analysis\n",
        "\n",
        "#### b) Did we have the right data?\n",
        "We had the right data for our analysis\n",
        "\n",
        "#### c) What can be done to improve the solution?\n",
        "We can improve the performance of our model by adding more LSTM layers, increasng our training data and increasing the timesteps"
      ]
    }
  ]
}